{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "16761\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def load_data_from_json(json_file_path):\n",
    "    \n",
    "    # Check if json_file_path is a list of JSON objects or a file path\n",
    "    if isinstance(json_file_path, list):\n",
    "        data_entries = json_file_path\n",
    "    else:\n",
    "        # Read JSON file containing data entries\n",
    "        with open(json_file_path, 'r') as f:\n",
    "            data_entries = json.load(f)\n",
    "    \n",
    "    return data_entries\n",
    "\n",
    "def split_data(data, num_data):\n",
    "    temp = []\n",
    "    data_len = len(data)//num_data\n",
    "    for i in range (num_data):\n",
    "        print(i)\n",
    "        temp.append(data[:data_len])\n",
    "        rm = temp[i]\n",
    "        data = [x for x in data if x not in rm]\n",
    "\n",
    "    return temp\n",
    "\n",
    "json_file_path = \"./data/train.json\"\n",
    "\n",
    "data = load_data_from_json(json_file_path)\n",
    "\n",
    "data = split_data(data,5)\n",
    "\n",
    "print(len(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16761\n"
     ]
    }
   ],
   "source": [
    "print(len(data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, num_splits):\n",
    "    # Make a copy of the data to avoid modifying the original\n",
    "    data_copy = data.copy()\n",
    "    \n",
    "    # Calculate approximately how many items should go in each split\n",
    "    total_items = len(data_copy)\n",
    "    items_per_split = total_items // num_splits\n",
    "    \n",
    "    # Create the splits\n",
    "    splits = []\n",
    "    for i in range(num_splits - 1):\n",
    "        print(f\"Creating split {i}\")\n",
    "        # Take the first 'items_per_split' items for this split\n",
    "        current_split = data_copy[:items_per_split]\n",
    "        splits.append(current_split)\n",
    "        # Remove these items from the remaining data\n",
    "        data_copy = data_copy[items_per_split:]\n",
    "    \n",
    "    # Add any remaining items to the last split\n",
    "    print(f\"Creating split {num_splits - 1}\")\n",
    "    splits.append(data_copy)\n",
    "    \n",
    "    # Write each split to a file\n",
    "    for i, split_data in enumerate(splits):\n",
    "        with open(f\"./data/train_{i}.json\", 'w') as f:\n",
    "            import json\n",
    "            f.write(json.dumps(split_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating split 0\n",
      "Creating split 1\n",
      "Creating split 2\n",
      "Creating split 3\n",
      "Creating split 4\n"
     ]
    }
   ],
   "source": [
    "split_data(data,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
